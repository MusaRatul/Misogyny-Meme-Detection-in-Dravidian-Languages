{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10580558,"sourceType":"datasetVersion","datasetId":6547966},{"sourceId":10590400,"sourceType":"datasetVersion","datasetId":6554381},{"sourceId":10590594,"sourceType":"datasetVersion","datasetId":6554526}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchvision\nimport os\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report, accuracy_score, f1_score\nfrom sklearn.metrics import precision_score, recall_score\nfrom tqdm import tqdm\nimport torch\nfrom transformers import AutoTokenizer, AutoModel\nfrom torchvision import models, transforms\nfrom PIL import Image\n\n# Device Configuration\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# Load and Preprocess Dataset\ndef load_data(csv_path, image_dir):\n    data = pd.read_csv(csv_path)\n    images = []\n    captions = []\n    labels = []\n\n    for idx in range(len(data)):\n        img_name = str(data.loc[idx, 'image_id'])\n        if not img_name.endswith(\".jpg\"):\n            img_name += \".jpg\"\n        img_path = os.path.join(image_dir, img_name)\n\n        if os.path.exists(img_path):\n            images.append(img_path)\n            captions.append(data.loc[idx, 'transcriptions'])\n            if 'labels' in data.columns:\n                labels.append(int(data.loc[idx, 'labels']))\n\n    return images, captions, labels\n\n# Feature Extraction Functions\ndef extract_text_features(captions, tokenizer, text_model, max_len=128):\n    text_features = []\n    for caption in tqdm(captions, desc=\"Extracting Text Features\"):\n        inputs = tokenizer(\n            caption, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=max_len\n        ).to(device)\n        with torch.no_grad():\n            outputs = text_model(**inputs)\n            text_features.append(outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy())\n    return np.array(text_features)\n\ndef extract_image_features(image_paths, visual_model, transform):\n    image_features = []\n    for img_path in tqdm(image_paths, desc=\"Extracting Image Features\"):\n        image = Image.open(img_path).convert(\"RGB\")\n        image = transform(image).unsqueeze(0).to(device)\n        with torch.no_grad():\n            features = visual_model(image).squeeze().cpu().numpy()\n        image_features.append(features)\n    return np.array(image_features)\n\nfrom sklearn.metrics import precision_score, recall_score\n\n# Training and Evaluation\ndef train_and_evaluate(X_train, y_train, X_test, y_test, model, model_name):\n    print(f\"\\nTraining {model_name}...\")\n    model.fit(X_train, y_train)\n    preds = model.predict(X_test)\n\n    # Compute metrics\n    precision = precision_score(y_test, preds, average=\"macro\")\n    recall = recall_score(y_test, preds, average=\"macro\")\n    macro_f1 = f1_score(y_test, preds, average=\"macro\")\n\n    print(f\"\\nResults for {model_name}:\")\n    print(classification_report(y_test, preds))\n    print(\"Accuracy:\", accuracy_score(y_test, preds))\n    print(f\"Macro Precision: {precision:.4f}\")\n    print(f\"Macro Recall: {recall:.4f}\")\n    print(f\"Macro F1 Score: {macro_f1:.4f}\")\n    return model\n\ndef main():\n    # Paths\n    train_csv = \"/kaggle/input/malayalam-labelled-dataset/Dataset with label/train/train.csv\"\n    train_images = \"/kaggle/input/malayalam-labelled-dataset/Dataset with label/train/images\"\n    test_csv = \"/kaggle/input/malayalam-labelled-dataset/Dataset with label/test/test_with_labels.csv\"\n    test_images = \"/kaggle/input/malayalam-labelled-dataset/Dataset with label/test/images\"\n\n    # Load Data\n    train_images, train_captions, train_labels = load_data(train_csv, train_images)\n    test_images, test_captions, test_labels = load_data(test_csv, test_images)\n\n    # Tokenizer and Models\n    tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indic-bert\")\n    text_model = AutoModel.from_pretrained(\"ai4bharat/indic-bert\").to(device)\n    visual_model = models.resnet50(pretrained=True)\n    visual_model = torch.nn.Sequential(*list(visual_model.children())[:-1]).to(device)\n\n    # Transform for Images\n    transform = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ])\n\n    # Feature Extraction\n    print(\"\\nExtracting Text Features...\")\n    train_text_features = extract_text_features(train_captions, tokenizer, text_model)\n    test_text_features = extract_text_features(test_captions, tokenizer, text_model)\n\n    print(\"\\nExtracting Image Features...\")\n    train_image_features = extract_image_features(train_images, visual_model, transform)\n    test_image_features = extract_image_features(test_images, visual_model, transform)\n\n    # Combine Features\n    X_train = np.concatenate([train_text_features, train_image_features], axis=1)\n    X_test = np.concatenate([test_text_features, test_image_features], axis=1)\n    y_train = np.array(train_labels)\n    y_test = np.array(test_labels)\n\n    # Define Models\n    classifiers = {\n        \"Logistic Regression\": LogisticRegression(max_iter=1000),\n        \"Support Vector Machine\": SVC(kernel=\"linear\", probability=True),\n        \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42)\n    }\n\n    # Train and Evaluate Models\n    for model_name, model in classifiers.items():\n        train_and_evaluate(X_train, y_train, X_test, y_test, model, model_name)\n\nif __name__ == \"__main__\":\n    main()\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-27T07:07:38.640645Z","iopub.execute_input":"2025-01-27T07:07:38.641049Z","iopub.status.idle":"2025-01-27T07:08:23.597355Z","shell.execute_reply.started":"2025-01-27T07:07:38.641015Z","shell.execute_reply":"2025-01-27T07:08:23.596356Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.5.1+cu121)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (2024.9.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.1->torchvision) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.1->torchvision) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torchvision) (2024.2.0)\nUsing device: cuda\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"\nExtracting Text Features...\n","output_type":"stream"},{"name":"stderr","text":"Extracting Text Features: 100%|██████████| 640/640 [00:05<00:00, 124.42it/s]\nExtracting Text Features: 100%|██████████| 200/200 [00:01<00:00, 123.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nExtracting Image Features...\n","output_type":"stream"},{"name":"stderr","text":"Extracting Image Features: 100%|██████████| 640/640 [00:19<00:00, 33.11it/s]\nExtracting Image Features: 100%|██████████| 200/200 [00:05<00:00, 34.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTraining Logistic Regression...\n\nResults for Logistic Regression:\n              precision    recall  f1-score   support\n\n           0       0.80      0.77      0.78       122\n           1       0.66      0.69      0.68        78\n\n    accuracy                           0.74       200\n   macro avg       0.73      0.73      0.73       200\nweighted avg       0.74      0.74      0.74       200\n\nAccuracy: 0.74\nMacro Precision: 0.7276\nMacro Recall: 0.7314\nMacro F1 Score: 0.7292\n\nTraining Support Vector Machine...\n\nResults for Support Vector Machine:\n              precision    recall  f1-score   support\n\n           0       0.80      0.80      0.80       122\n           1       0.68      0.68      0.68        78\n\n    accuracy                           0.75       200\n   macro avg       0.74      0.74      0.74       200\nweighted avg       0.75      0.75      0.75       200\n\nAccuracy: 0.75\nMacro Precision: 0.7373\nMacro Recall: 0.7373\nMacro F1 Score: 0.7373\n\nTraining Random Forest...\n\nResults for Random Forest:\n              precision    recall  f1-score   support\n\n           0       0.73      0.81      0.77       122\n           1       0.64      0.53      0.58        78\n\n    accuracy                           0.70       200\n   macro avg       0.68      0.67      0.67       200\nweighted avg       0.69      0.70      0.69       200\n\nAccuracy: 0.7\nMacro Precision: 0.6843\nMacro Recall: 0.6686\nMacro F1 Score: 0.6725\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Install required libraries\n!pip install torchvision transformers\n\n# Import libraries\nimport os\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModel\nfrom torchvision import models, transforms\nfrom PIL import Image\n\n# Device Configuration\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# Paths\ntrain_csv_path = \"/kaggle/input/malayalam-labelled-dataset/Dataset with label/train/train.csv\"\ntrain_images_path = \"/kaggle/input/malayalam-labelled-dataset/Dataset with label/train/images\"\ndev_csv_path = \"/kaggle/input/malayalam-labelled-dataset/Dataset with label/dev/dev.csv\"\ndev_images_path = \"/kaggle/input/malayalam-labelled-dataset/Dataset with label/dev/images\"\ntest_csv_path = \"/kaggle/input/malayalam-labelled-dataset/Dataset with label/test/test_with_labels.csv\"\ntest_images_path = \"/kaggle/input/malayalam-labelled-dataset/Dataset with label/test/images\"\n\n# Load and Preprocess Dataset\ndef load_data(csv_path, image_dir):\n    data = pd.read_csv(csv_path)\n    images = []\n    captions = []\n    labels = []\n\n    for idx in range(len(data)):\n        img_name = str(data.loc[idx, 'image_id'])\n        if not img_name.endswith(\".jpg\"):\n            img_name += \".jpg\"\n        img_path = os.path.join(image_dir, img_name)\n\n        if os.path.exists(img_path):\n            images.append(img_path)\n            captions.append(data.loc[idx, 'transcriptions'])\n            if 'labels' in data.columns:\n                labels.append(int(data.loc[idx, 'labels']))\n\n    return images, captions, labels\n\n# Feature Extraction Functions\ndef extract_text_features(captions, tokenizer, text_model, max_len=128):\n    text_features = []\n    for caption in tqdm(captions, desc=\"Extracting Text Features\"):\n        inputs = tokenizer(\n            caption, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=max_len\n        ).to(device)\n        with torch.no_grad():\n            outputs = text_model(**inputs)\n            text_features.append(outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy())\n    return np.array(text_features)\n\ndef extract_image_features(image_paths, visual_model, transform):\n    image_features = []\n    visual_model.eval()  # Ensure the model is in evaluation mode\n    for img_path in tqdm(image_paths, desc=\"Extracting Image Features\"):\n        image = Image.open(img_path).convert(\"RGB\")\n        image = transform(image).unsqueeze(0).to(device)\n        with torch.no_grad():\n            features = visual_model(image).squeeze().cpu().numpy()\n        image_features.append(features)\n    return np.array(image_features)\n\n# Evaluation Function\ndef evaluate_model(y_true, y_pred, model_name):\n    print(f\"\\nResults for {model_name}:\")\n    print(classification_report(y_true, y_pred))\n    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n    print(\"Macro Precision:\", precision_score(y_true, y_pred, average=\"macro\"))\n    print(\"Macro Recall:\", recall_score(y_true, y_pred, average=\"macro\"))\n    print(\"Macro F1 Score:\", f1_score(y_true, y_pred, average=\"macro\"))\n\n# CNN Model\nclass CNNModel(nn.Module):\n    def __init__(self, input_dim, num_classes):\n        super(CNNModel, self).__init__()\n        self.conv1 = nn.Conv1d(in_channels=1, out_channels=128, kernel_size=3, padding=1)\n        self.pool = nn.MaxPool1d(kernel_size=2)\n        self.fc1 = nn.Linear(128 * (input_dim // 2), 64)\n        self.fc2 = nn.Linear(64, num_classes)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.5)\n\n    def forward(self, x):\n        x = x.unsqueeze(1)  # Add a dummy channel dimension: (batch_size, 1, input_dim)\n        x = self.relu(self.conv1(x))\n        x = self.pool(x)\n        x = x.view(x.size(0), -1)  # Flatten\n        x = self.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n        return x\n\n# BiLSTM Model\nclass BiLSTMModel(nn.Module):\n    def __init__(self, input_dim, hidden_dim, num_classes):\n        super(BiLSTMModel, self).__init__()\n        self.hidden_dim = hidden_dim\n        self.lstm = nn.LSTM(input_dim, hidden_dim, bidirectional=True, batch_first=True)\n        self.fc = nn.Linear(hidden_dim * 2, num_classes)\n        self.dropout = nn.Dropout(0.5)\n\n    def forward(self, x):\n        x = x.unsqueeze(1)  # Add a dummy sequence dimension: (batch_size, 1, input_dim)\n        h_lstm, _ = self.lstm(x)\n        out = self.fc(h_lstm[:, -1, :])  # Use the last hidden state\n        return out\n\n# BiLSTM + CNN Model\nclass BiLSTMCNNModel(nn.Module):\n    def __init__(self, input_dim, hidden_dim, num_classes):\n        super(BiLSTMCNNModel, self).__init__()\n        self.lstm = nn.LSTM(input_dim, hidden_dim, bidirectional=True, batch_first=True)\n        self.conv1 = nn.Conv1d(in_channels=hidden_dim * 2, out_channels=128, kernel_size=3, padding=1)\n        self.fc = nn.Linear(128, num_classes)\n        self.dropout = nn.Dropout(0.5)\n\n    def forward(self, x):\n        # Debugging: Print input shape\n        print(f\"Input shape: {x.shape}\")\n\n        if len(x.shape) == 2:  # (batch_size, input_dim)\n            x = x.unsqueeze(1)  # (batch_size, 1, input_dim)\n\n        # LSTM processing\n        h_lstm, _ = self.lstm(x)  # (batch_size, sequence_length, hidden_dim * 2)\n        print(f\"LSTM output shape: {h_lstm.shape}\")\n\n        h_lstm = h_lstm.permute(0, 2, 1)  # (batch_size, hidden_dim * 2, sequence_length)\n        print(f\"Permuted LSTM output shape: {h_lstm.shape}\")\n\n        # Convolution\n        h_conv = nn.functional.relu(self.conv1(h_lstm))  # (batch_size, 128, sequence_length)\n        print(f\"Conv1d output shape: {h_conv.shape}\")\n\n        # Global average pooling\n        h_pool = torch.mean(h_conv, dim=2)  # (batch_size, 128)\n        print(f\"Global average pooling output shape: {h_pool.shape}\")\n\n        # Fully connected layer\n        out = self.dropout(self.fc(h_pool))  # (batch_size, num_classes)\n        print(f\"Final output shape: {out.shape}\")\n\n        return out\n        \n# Training and Evaluation Function for CNN\ndef train_and_evaluate_cnn(X_train, y_train, X_dev, y_dev, X_test, y_test, input_dim, num_classes, epochs=10, batch_size=32):\n    model = CNNModel(input_dim, num_classes).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n\n    # Convert data to PyTorch tensors\n    X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n    y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n    X_dev = torch.tensor(X_dev, dtype=torch.float32).to(device)\n    y_dev = torch.tensor(y_dev, dtype=torch.long).to(device)\n    X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n    y_test = torch.tensor(y_test, dtype=torch.long).to(device)\n\n    # DataLoader\n    train_dataset = TensorDataset(X_train, y_train)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    # Training\n    for epoch in range(epochs):\n        model.train()\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n        scheduler.step()\n\n        # Validation\n        model.eval()\n        with torch.no_grad():\n            outputs = model(X_dev)\n            _, preds = torch.max(outputs, 1)\n            val_loss = criterion(outputs, y_dev)\n            print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}, Val Loss: {val_loss.item()}\")\n\n    # Evaluation on Test Data\n    model.eval()\n    with torch.no_grad():\n        outputs = model(X_test)\n        _, preds = torch.max(outputs, 1)\n        evaluate_model(y_test.cpu(), preds.cpu(), \"CNN\")\n\n# Training and Evaluation Function for BiLSTM\ndef train_and_evaluate_bilstm(X_train, y_train, X_dev, y_dev, X_test, y_test, input_dim, hidden_dim, num_classes, epochs=10, batch_size=32):\n    model = BiLSTMModel(input_dim, hidden_dim, num_classes).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n\n    # Convert data to PyTorch tensors\n    X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n    y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n    X_dev = torch.tensor(X_dev, dtype=torch.float32).to(device)\n    y_dev = torch.tensor(y_dev, dtype=torch.long).to(device)\n    X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n    y_test = torch.tensor(y_test, dtype=torch.long).to(device)\n\n    # DataLoader\n    train_dataset = TensorDataset(X_train, y_train)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    # Training\n    for epoch in range(epochs):\n        model.train()\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n        scheduler.step()\n\n        # Validation\n        model.eval()\n        with torch.no_grad():\n            outputs = model(X_dev)\n            _, preds = torch.max(outputs, 1)\n            val_loss = criterion(outputs, y_dev)\n            print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}, Val Loss: {val_loss.item()}\")\n\n    # Evaluation on Test Data\n    model.eval()\n    with torch.no_grad():\n        outputs = model(X_test)\n        _, preds = torch.max(outputs, 1)\n        evaluate_model(y_test.cpu(), preds.cpu(), \"BiLSTM\")\n\n# Training and Evaluation Function for BiLSTM + CNN\ndef train_and_evaluate_bilstm_cnn(X_train, y_train, X_dev, y_dev, X_test, y_test, input_dim, hidden_dim, num_classes, epochs=10, batch_size=32):\n    model = BiLSTMCNNModel(input_dim, hidden_dim, num_classes).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n\n    # Convert data to PyTorch tensors\n    X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n    y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n    X_dev = torch.tensor(X_dev, dtype=torch.float32).to(device)\n    y_dev = torch.tensor(y_dev, dtype=torch.long).to(device)\n    X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n    y_test = torch.tensor(y_test, dtype=torch.long).to(device)\n\n    # DataLoader\n    train_dataset = TensorDataset(X_train, y_train)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    # Training\n    for epoch in range(epochs):\n        model.train()\n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n        scheduler.step()\n\n        # Validation\n        model.eval()\n        with torch.no_grad():\n            outputs = model(X_dev)\n            _, preds = torch.max(outputs, 1)\n            val_loss = criterion(outputs, y_dev)\n            print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}, Val Loss: {val_loss.item()}\")\n\n    # Evaluation on Test Data\n    model.eval()\n    with torch.no_grad():\n        outputs = model(X_test)\n        _, preds = torch.max(outputs, 1)\n        evaluate_model(y_test.cpu(), preds.cpu(), \"BiLSTM + CNN\")\n        \n# Main Function\n\ndef main():\n    # Load Data\n    train_image_paths, train_captions, train_labels = load_data(train_csv_path, train_images_path)\n    dev_image_paths, dev_captions, dev_labels = load_data(dev_csv_path, dev_images_path)\n    test_image_paths, test_captions, test_labels = load_data(test_csv_path, test_images_path)\n\n    # Define Tokenizer and Text Model\n    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n    text_model = AutoModel.from_pretrained(\"bert-base-multilingual-cased\").to(device)\n\n    # Define Visual Model\n    visual_model = models.resnet50(pretrained=True)\n    visual_model.fc = nn.Identity()  # Use the penultimate layer as the feature extractor\n    visual_model = visual_model.to(device)\n\n    # Define Image Transform\n    transform = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ])\n\n    # Extract Features\n    print(\"Extracting Text Features...\")\n    train_text_features = extract_text_features(train_captions, tokenizer, text_model)\n    dev_text_features = extract_text_features(dev_captions, tokenizer, text_model)\n    test_text_features = extract_text_features(test_captions, tokenizer, text_model)\n\n    print(\"Extracting Image Features...\")\n    train_image_features = extract_image_features(train_image_paths, visual_model, transform)\n    dev_image_features = extract_image_features(dev_image_paths, visual_model, transform)\n    test_image_features = extract_image_features(test_image_paths, visual_model, transform)\n\n    # Combine Features\n    train_features = np.hstack((train_text_features, train_image_features))\n    dev_features = np.hstack((dev_text_features, dev_image_features))\n    test_features = np.hstack((test_text_features, test_image_features))\n\n    # Train and Evaluate Models\n    input_dim = train_features.shape[1]\n    num_classes = len(set(train_labels))\n    hidden_dim = 128  # For BiLSTM\n\n    print(\"\\nTraining CNN Model...\")\n    train_and_evaluate_cnn(train_features, train_labels, dev_features, dev_labels, test_features, test_labels, input_dim, num_classes)\n\n    print(\"\\nTraining BiLSTM Model...\")\n    train_and_evaluate_bilstm(train_features, train_labels, dev_features, dev_labels, test_features, test_labels, input_dim, hidden_dim, num_classes)\n\n    print(\"\\nTraining BiLSTM + CNN Model...\")\n    train_and_evaluate_bilstm_cnn(train_features, train_labels, dev_features, dev_labels, test_features, test_labels, input_dim, hidden_dim, num_classes)\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T07:11:57.038747Z","iopub.execute_input":"2025-01-27T07:11:57.039111Z","iopub.status.idle":"2025-01-27T07:12:47.360183Z","shell.execute_reply.started":"2025-01-27T07:11:57.039079Z","shell.execute_reply":"2025-01-27T07:12:47.359212Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.5.1+cu121)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (2024.9.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.1->torchvision) (1.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.1->torchvision) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torchvision) (2024.2.0)\nUsing device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"344bdaf8ff2b420b928c2f5b4e04d811"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2154d619e17c4defb8bde8f04d96e101"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8101da1da4448d585cb19a9364e57e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"982e417a74444ce6a5cf16138dc7e594"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f010dfd4d2f4e499498b10acc21b2b9"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Extracting Text Features...\n","output_type":"stream"},{"name":"stderr","text":"Extracting Text Features: 100%|██████████| 640/640 [00:05<00:00, 109.22it/s]\nExtracting Text Features: 100%|██████████| 160/160 [00:01<00:00, 108.82it/s]\nExtracting Text Features: 100%|██████████| 200/200 [00:01<00:00, 110.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting Image Features...\n","output_type":"stream"},{"name":"stderr","text":"Extracting Image Features: 100%|██████████| 640/640 [00:18<00:00, 35.08it/s]\nExtracting Image Features: 100%|██████████| 160/160 [00:04<00:00, 33.56it/s]\nExtracting Image Features: 100%|██████████| 200/200 [00:05<00:00, 38.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTraining CNN Model...\nEpoch 1/10, Loss: 0.687190055847168, Val Loss: 0.6525322198867798\nEpoch 2/10, Loss: 0.7020477652549744, Val Loss: 0.6450766324996948\nEpoch 3/10, Loss: 0.7403168082237244, Val Loss: 0.6063914895057678\nEpoch 4/10, Loss: 0.6555379033088684, Val Loss: 0.6180673241615295\nEpoch 5/10, Loss: 0.6114636063575745, Val Loss: 0.5684558153152466\nEpoch 6/10, Loss: 0.6048188805580139, Val Loss: 0.5832468867301941\nEpoch 7/10, Loss: 0.6645528078079224, Val Loss: 0.5992092490196228\nEpoch 8/10, Loss: 0.67783522605896, Val Loss: 0.5824341773986816\nEpoch 9/10, Loss: 0.6288920640945435, Val Loss: 0.5877923369407654\nEpoch 10/10, Loss: 0.6097722053527832, Val Loss: 0.5810610055923462\n\nResults for CNN:\n              precision    recall  f1-score   support\n\n           0       0.61      1.00      0.76       122\n           1       0.00      0.00      0.00        78\n\n    accuracy                           0.61       200\n   macro avg       0.30      0.50      0.38       200\nweighted avg       0.37      0.61      0.46       200\n\nAccuracy: 0.61\nMacro Precision: 0.305\nMacro Recall: 0.5\nMacro F1 Score: 0.37888198757763975\n\nTraining BiLSTM Model...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10, Loss: 0.47954320907592773, Val Loss: 0.4826173186302185\nEpoch 2/10, Loss: 0.353268563747406, Val Loss: 0.5374100208282471\nEpoch 3/10, Loss: 0.23191724717617035, Val Loss: 0.506673276424408\nEpoch 4/10, Loss: 0.33520039916038513, Val Loss: 0.6103768348693848\nEpoch 5/10, Loss: 0.1951366364955902, Val Loss: 0.5820045471191406\nEpoch 6/10, Loss: 0.2093452513217926, Val Loss: 0.4393930435180664\nEpoch 7/10, Loss: 0.16213460266590118, Val Loss: 0.4827810227870941\nEpoch 8/10, Loss: 0.17968909442424774, Val Loss: 0.48018330335617065\nEpoch 9/10, Loss: 0.19861088693141937, Val Loss: 0.4990668296813965\nEpoch 10/10, Loss: 0.2400296926498413, Val Loss: 0.4801900386810303\n\nResults for BiLSTM:\n              precision    recall  f1-score   support\n\n           0       0.83      0.87      0.85       122\n           1       0.78      0.73      0.75        78\n\n    accuracy                           0.81       200\n   macro avg       0.81      0.80      0.80       200\nweighted avg       0.81      0.81      0.81       200\n\nAccuracy: 0.815\nMacro Precision: 0.8077337935497788\nMacro Recall: 0.7998108448928121\nMacro F1 Score: 0.8031862549535892\n\nTraining BiLSTM + CNN Model...\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([160, 2816])\nLSTM output shape: torch.Size([160, 1, 256])\nPermuted LSTM output shape: torch.Size([160, 256, 1])\nConv1d output shape: torch.Size([160, 128, 1])\nGlobal average pooling output shape: torch.Size([160, 128])\nFinal output shape: torch.Size([160, 2])\nEpoch 1/10, Loss: 0.4480428695678711, Val Loss: 0.5224463939666748\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([160, 2816])\nLSTM output shape: torch.Size([160, 1, 256])\nPermuted LSTM output shape: torch.Size([160, 256, 1])\nConv1d output shape: torch.Size([160, 128, 1])\nGlobal average pooling output shape: torch.Size([160, 128])\nFinal output shape: torch.Size([160, 2])\nEpoch 2/10, Loss: 0.4719441533088684, Val Loss: 0.4350588321685791\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([160, 2816])\nLSTM output shape: torch.Size([160, 1, 256])\nPermuted LSTM output shape: torch.Size([160, 256, 1])\nConv1d output shape: torch.Size([160, 128, 1])\nGlobal average pooling output shape: torch.Size([160, 128])\nFinal output shape: torch.Size([160, 2])\nEpoch 3/10, Loss: 0.6424075365066528, Val Loss: 0.4168333411216736\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([160, 2816])\nLSTM output shape: torch.Size([160, 1, 256])\nPermuted LSTM output shape: torch.Size([160, 256, 1])\nConv1d output shape: torch.Size([160, 128, 1])\nGlobal average pooling output shape: torch.Size([160, 128])\nFinal output shape: torch.Size([160, 2])\nEpoch 4/10, Loss: 0.34875917434692383, Val Loss: 0.42668646574020386\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([160, 2816])\nLSTM output shape: torch.Size([160, 1, 256])\nPermuted LSTM output shape: torch.Size([160, 256, 1])\nConv1d output shape: torch.Size([160, 128, 1])\nGlobal average pooling output shape: torch.Size([160, 128])\nFinal output shape: torch.Size([160, 2])\nEpoch 5/10, Loss: 0.4292442798614502, Val Loss: 0.4293581545352936\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([160, 2816])\nLSTM output shape: torch.Size([160, 1, 256])\nPermuted LSTM output shape: torch.Size([160, 256, 1])\nConv1d output shape: torch.Size([160, 128, 1])\nGlobal average pooling output shape: torch.Size([160, 128])\nFinal output shape: torch.Size([160, 2])\nEpoch 6/10, Loss: 0.30783528089523315, Val Loss: 0.4804958701133728\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([160, 2816])\nLSTM output shape: torch.Size([160, 1, 256])\nPermuted LSTM output shape: torch.Size([160, 256, 1])\nConv1d output shape: torch.Size([160, 128, 1])\nGlobal average pooling output shape: torch.Size([160, 128])\nFinal output shape: torch.Size([160, 2])\nEpoch 7/10, Loss: 0.2844179570674896, Val Loss: 0.431526243686676\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([160, 2816])\nLSTM output shape: torch.Size([160, 1, 256])\nPermuted LSTM output shape: torch.Size([160, 256, 1])\nConv1d output shape: torch.Size([160, 128, 1])\nGlobal average pooling output shape: torch.Size([160, 128])\nFinal output shape: torch.Size([160, 2])\nEpoch 8/10, Loss: 0.28998002409935, Val Loss: 0.4558679461479187\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([160, 2816])\nLSTM output shape: torch.Size([160, 1, 256])\nPermuted LSTM output shape: torch.Size([160, 256, 1])\nConv1d output shape: torch.Size([160, 128, 1])\nGlobal average pooling output shape: torch.Size([160, 128])\nFinal output shape: torch.Size([160, 2])\nEpoch 9/10, Loss: 0.22485144436359406, Val Loss: 0.4572068154811859\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([32, 2816])\nLSTM output shape: torch.Size([32, 1, 256])\nPermuted LSTM output shape: torch.Size([32, 256, 1])\nConv1d output shape: torch.Size([32, 128, 1])\nGlobal average pooling output shape: torch.Size([32, 128])\nFinal output shape: torch.Size([32, 2])\nInput shape: torch.Size([160, 2816])\nLSTM output shape: torch.Size([160, 1, 256])\nPermuted LSTM output shape: torch.Size([160, 256, 1])\nConv1d output shape: torch.Size([160, 128, 1])\nGlobal average pooling output shape: torch.Size([160, 128])\nFinal output shape: torch.Size([160, 2])\nEpoch 10/10, Loss: 0.32497406005859375, Val Loss: 0.47617435455322266\nInput shape: torch.Size([200, 2816])\nLSTM output shape: torch.Size([200, 1, 256])\nPermuted LSTM output shape: torch.Size([200, 256, 1])\nConv1d output shape: torch.Size([200, 128, 1])\nGlobal average pooling output shape: torch.Size([200, 128])\nFinal output shape: torch.Size([200, 2])\n\nResults for BiLSTM + CNN:\n              precision    recall  f1-score   support\n\n           0       0.83      0.87      0.85       122\n           1       0.78      0.72      0.75        78\n\n    accuracy                           0.81       200\n   macro avg       0.80      0.79      0.80       200\nweighted avg       0.81      0.81      0.81       200\n\nAccuracy: 0.81\nMacro Precision: 0.8029513888888888\nMacro Recall: 0.7934005884825557\nMacro F1 Score: 0.7973333333333333\n","output_type":"stream"}],"execution_count":6}]}